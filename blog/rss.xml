<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>llm-chain Blog</title>
        <link>https://docs.llm-chain.xyz/blog</link>
        <description>llm-chain Blog</description>
        <lastBuildDate>Fri, 14 Apr 2023 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Using ChatGPT in Rust with llm-chain]]></title>
            <link>https://docs.llm-chain.xyz/blog/using-chatgpt-in-rust</link>
            <guid>https://docs.llm-chain.xyz/blog/using-chatgpt-in-rust</guid>
            <pubDate>Fri, 14 Apr 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[In this blog post, we'll explore how to use ChatGPT in Rust with the help of the llm-chain library. We will walk through a simple example that demonstrates how to generate responses using OpenAI's ChatGPT model.]]></description>
            <content:encoded><![CDATA[<p>In this blog post, we'll explore how to use ChatGPT in Rust with the help of the <code>llm-chain</code> library. We will walk through a simple example that demonstrates how to generate responses using OpenAI's ChatGPT model.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-started">Getting Started<a href="#getting-started" class="hash-link" aria-label="Direct link to Getting Started" title="Direct link to Getting Started">​</a></h2><p>First, let's start by installing the necessary packages using <code>cargo add</code>. You will need the <code>llm-chain</code> and <code>llm-chain-openai</code> libraries:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cargo add llm-chain llm-chain-openai</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Now, let's dive into the code:</p><div class="language-rust codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-rust codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">use llm_chain::{traits::StepExt, Parameters};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">use llm_chain_openai::chatgpt::{Executor, Model, Role, Step};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#[tokio::main(flavor = "current_thread")]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">async fn main() {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    let exec = Executor::new_default();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    let chain = Step::new(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Model::ChatGPT3_5Turbo,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                Role::System,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                "You are a helpful assistant",</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            ),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            (Role::User, "Tell me about the Rust programming language"),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .to_chain();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    let res = chain.run(Parameters::new(), &amp;exec).await.unwrap();</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    println!("{:?}", res);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In the code snippet above, we begin by importing the necessary modules and functions from the <code>llm-chain</code> and <code>llm-chain-openai</code> libraries. We then define a simple <code>main</code> function that uses the <code>Executor</code> and <code>Step</code> structs to create a conversational chain.</p><p>The <code>Model::ChatGPT3_5Turbo</code> model is used as the language model in this example. We also define two steps in the conversation: the first one sets the role of the assistant and the second one asks a question about the Rust programming language.</p><p>Finally, we execute the conversation chain using the <code>run</code> method and print the generated response.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="wrapping-up">Wrapping Up<a href="#wrapping-up" class="hash-link" aria-label="Direct link to Wrapping Up" title="Direct link to Wrapping Up">​</a></h2><p>As you can see, using ChatGPT in Rust with <code>llm-chain</code> is a straightforward and efficient process. The library makes it easy to build and manage conversational agents in Rust, allowing developers to focus on creating more powerful and interactive applications.</p><p>To continue learning about ChatGPT in Rust and how to make the most of the <code>llm-chain</code> library, try our <a href="https://chat.openai.com/docs/getting-started-tutorial/index" target="_blank" rel="noopener noreferrer">tutorial</a> .</p>]]></content:encoded>
            <category>llm-chain</category>
            <category>introduction</category>
            <category>chatgpt</category>
            <category>rust</category>
        </item>
        <item>
            <title><![CDATA[Unleashing the Power of Large Language Models with LLM-chain]]></title>
            <link>https://docs.llm-chain.xyz/blog/introducing-llm-chain</link>
            <guid>https://docs.llm-chain.xyz/blog/introducing-llm-chain</guid>
            <pubDate>Mon, 10 Apr 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[We're excited to announce the release of LLM-chain, a Rust library designed to help developers work with Large Language Models (LLMs) more effectively. Our primary focus is on providing robust support for prompt templates and chaining together prompts in multi-step chains, enabling complex tasks that LLMs can't handle in a single step. This includes, but is not limited to, summarizing lengthy texts or performing advanced data processing tasks.]]></description>
            <content:encoded><![CDATA[<p>We're excited to announce the release of LLM-chain, a Rust library designed to help developers work with Large Language Models (LLMs) more effectively. Our primary focus is on providing robust support for prompt templates and chaining together prompts in multi-step chains, enabling complex tasks that LLMs can't handle in a single step. This includes, but is not limited to, summarizing lengthy texts or performing advanced data processing tasks.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="features-of-llm-chain">Features of LLM-chain<a href="#features-of-llm-chain" class="hash-link" aria-label="Direct link to Features of LLM-chain" title="Direct link to Features of LLM-chain">​</a></h2><p>LLM-chain comes with a variety of features that make it easier to work with LLMs, including:</p><ul><li><strong>Prompt templates</strong>: Create reusable and easily customizable prompt templates for consistent and structured interactions with LLMs.</li><li><strong>Chains</strong>: Build powerful chains of prompts that allow you to execute more complex tasks, step by step, leveraging the full potential of LLMs.</li><li><strong>ChatGPT support</strong>: Currently supports ChatGPT models, with plans to add support for more LLMs in the future, such as LLaMa and Stanford's Alpaca models.</li><li><strong>Tools</strong>: Enhance your AI agents' capabilities by giving them access to various tools, such as running Bash commands, executing Python scripts, or performing web searches, enabling more complex and powerful interactions.</li><li><strong>Extensibility</strong>: Designed with extensibility in mind, making it easy to integrate additional LLMs as the ecosystem grows and new models are developed.</li><li><strong>Community-driven</strong>: We welcome and encourage contributions from the community to help improve and expand the capabilities of LLM-chain.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="connect-with-us">Connect with Us<a href="#connect-with-us" class="hash-link" aria-label="Direct link to Connect with Us" title="Direct link to Connect with Us">​</a></h2><p>If you have any questions, suggestions, or feedback, feel free to join our <a href="https://discord.gg/kewN9Gtjt2" target="_blank" rel="noopener noreferrer">Discord community</a>. We're always excited to hear from our users and learn about your experiences with LLM-chain.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-started-with-llm-chain">Getting Started with LLM-chain<a href="#getting-started-with-llm-chain" class="hash-link" aria-label="Direct link to Getting Started with LLM-chain" title="Direct link to Getting Started with LLM-chain">​</a></h2><p>Check out our <a href="https://github.com/sobelio/llm-chain" target="_blank" rel="noopener noreferrer">Github repository</a> or the <a href="https://docs.rs/llm-chain" target="_blank" rel="noopener noreferrer">documentation</a> to get started.</p>]]></content:encoded>
            <category>llm-chain</category>
            <category>introduction</category>
            <category>large language models</category>
            <category>rust</category>
        </item>
    </channel>
</rss>