"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[671],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>g});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=r.createContext({}),c=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=c(e.components);return r.createElement(l.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=c(n),m=o,g=u["".concat(l,".").concat(m)]||u[m]||d[m]||a;return n?r.createElement(g,i(i({ref:t},p),{},{components:n})):r.createElement(g,i({ref:t},p))}));function g(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,i=new Array(a);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:o,i[1]=s;for(var c=2;c<a;c++)i[c]=n[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},9881:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>s,toc:()=>c});var r=n(7462),o=(n(7294),n(3905));const a={id:"introduction",title:"Introduction",sidebar_label:"Introduction",sidebar_position:0},i="Welcome to LLM-chain",s={unversionedId:"introduction",id:"introduction",title:"Introduction",description:"LLM-chain is a collection of Rust crates designed to help you work with Large Language Models (LLMs) more effectively. Our primary focus is on providing robust support for prompt templates and chaining together prompts in multi-step chains, enabling complex tasks that LLMs can't handle in a single step. This includes, but is not limited to, summarizing lengthy texts or performing advanced data processing tasks.",source:"@site/docs/intro.md",sourceDirName:".",slug:"/introduction",permalink:"/llm-chain/docs/introduction",draft:!1,editUrl:"https://github.com/sobelio/llm-chain/tree/main/docs/docs/intro.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{id:"introduction",title:"Introduction",sidebar_label:"Introduction",sidebar_position:0},sidebar:"sidebar",next:{title:"Simple Text Generation",permalink:"/llm-chain/docs/basic-text-generation"}},l={},c=[{value:"Features",id:"features",level:2},{value:"Getting Started",id:"getting-started",level:2},{value:"Connect with Us",id:"connect-with-us",level:2}],p={toc:c},u="wrapper";function d(e){let{components:t,...n}=e;return(0,o.kt)(u,(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"welcome-to-llm-chain"},"Welcome to LLM-chain"),(0,o.kt)("p",null,"LLM-chain is a collection of Rust crates designed to help you work with Large Language Models (LLMs) more effectively. Our primary focus is on providing robust support for prompt templates and chaining together prompts in multi-step chains, enabling complex tasks that LLMs can't handle in a single step. This includes, but is not limited to, summarizing lengthy texts or performing advanced data processing tasks."),(0,o.kt)("h2",{id:"features"},"Features"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Prompt templates"),": Create reusable and easily customizable prompt templates for consistent and structured interactions with LLMs."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Chains"),": Build powerful chains of prompts that allow you to execute more complex tasks, step by step, leveraging the full potential of LLMs."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"ChatGPT support"),": Supports ChatGPT models, with plans to add OpenAI's other models in the future."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"LLaMa support"),": Provides seamless integration with LLaMa models, enabling natural language understanding and generation tasks with Facebook's research models."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Alpaca support"),": Incorporates support for Stanford's Alpaca models, expanding the range of available language models for advanced AI applications."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Tools"),": Enhance your AI agents' capabilities by giving them access to various tools, such as running Bash commands, executing Python scripts, or performing web searches, enabling more complex and powerful interactions."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Extensibility"),": Designed with extensibility in mind, making it easy to integrate additional LLMs as the ecosystem grows."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Community-driven"),": We welcome and encourage contributions from the community to help improve and expand the capabilities of LLM-chain.")),(0,o.kt)("h2",{id:"getting-started"},"Getting Started"),(0,o.kt)("p",null,"To start using LLM-chain, add it as a dependency in your ",(0,o.kt)("inlineCode",{parentName:"p"},"Cargo.toml"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-toml"},'[dependencies]\nllm-chain = "0.1.0"\nllm-chain-openai = "0.1.0\n')),(0,o.kt)("h2",{id:"connect-with-us"},"Connect with Us"),(0,o.kt)("p",null,"We're always excited to hear from our users and learn about your experiences with LLM-chain. If you have any questions, suggestions, or feedback, feel free to open an issue or join our community discussions."),(0,o.kt)("p",null,"We hope you enjoy using LLM-chain to unlock the full potential of Large Language Models in your projects. Happy coding! \ud83c\udf89"))}d.isMDXComponent=!0}}]);