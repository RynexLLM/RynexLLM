"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[53],{1109:t=>{t.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"sidebar":[{"type":"link","label":"Introduction","href":"/llm-chain/docs/introduction","docId":"introduction"},{"type":"category","label":"Tutorial","collapsible":true,"collapsed":false,"customProps":{"description":"A tutorial for getting started with llm-chain"},"className":"red","items":[{"type":"link","label":"Getting started","href":"/llm-chain/docs/getting-started-tutorial/index","docId":"getting-started-tutorial/index"},{"type":"link","label":"Setting up a project with llm-chain","href":"/llm-chain/docs/getting-started-tutorial/setting-up-a-project","docId":"getting-started-tutorial/setting-up-a-project"},{"type":"link","label":"Generating Your First LLM Output","href":"/llm-chain/docs/getting-started-tutorial/generating-your-first-llm-output","docId":"getting-started-tutorial/generating-your-first-llm-output"},{"type":"link","label":"Using Prompt Templates and Parameters","href":"/llm-chain/docs/getting-started-tutorial/using-prompt-templates-and-parameters","docId":"getting-started-tutorial/using-prompt-templates-and-parameters"},{"type":"link","label":"Creating Your First Sequential Chain","href":"/llm-chain/docs/getting-started-tutorial/building-a-multi-step-chain","docId":"getting-started-tutorial/building-a-multi-step-chain"},{"type":"link","label":"Summarizing Text with Map-Reduce in LLM-Chain","href":"/llm-chain/docs/getting-started-tutorial/summarizing-text-with-map-reduce","docId":"getting-started-tutorial/summarizing-text-with-map-reduce"}],"href":"/llm-chain/docs/category/tutorial"}]},"docs":{"getting-started-tutorial/building-a-multi-step-chain":{"id":"getting-started-tutorial/building-a-multi-step-chain","title":"Creating Your First Sequential Chain","description":"Having problems? Don\'t worry reach out on discord and we will help you out.","sidebar":"sidebar"},"getting-started-tutorial/generating-your-first-llm-output":{"id":"getting-started-tutorial/generating-your-first-llm-output","title":"Generating Your First LLM Output","description":"Having problems? Don\'t worry reach out on discord and we will help you out.","sidebar":"sidebar"},"getting-started-tutorial/index":{"id":"getting-started-tutorial/index","title":"Getting started","description":"Welcome to the Getting Started tutorial for llm-chain! This series of articles will guide you through the process of installing, setting up, and using the llm-chain library to make cool applications for LLMs. As you progress through the tutorials, you\'ll learn about generating text, using prompt templates, creating sequential chains, and summarizing text with map-reduce. We hope these tutorials provide you with a solid foundation to build upon and inspire you to create unique and innovative solutions using llm-chain. Let\'s get started!","sidebar":"sidebar"},"getting-started-tutorial/setting-up-a-project":{"id":"getting-started-tutorial/setting-up-a-project","title":"Setting up a project with llm-chain","description":"Having problems? Don\'t worry reach out on discord and we will help you out.","sidebar":"sidebar"},"getting-started-tutorial/summarizing-text-with-map-reduce":{"id":"getting-started-tutorial/summarizing-text-with-map-reduce","title":"Summarizing Text with Map-Reduce in LLM-Chain","description":"Having problems? Don\'t worry reach out on discord and we will help you out.","sidebar":"sidebar"},"getting-started-tutorial/using-prompt-templates-and-parameters":{"id":"getting-started-tutorial/using-prompt-templates-and-parameters","title":"Using Prompt Templates and Parameters","description":"Having problems? Don\'t worry reach out on discord and we will help you out.","sidebar":"sidebar"},"introduction":{"id":"introduction","title":"Introduction","description":"LLM-chain is a collection of Rust crates designed to help you work with Large Language Models (LLMs) more effectively. Our primary focus is on providing robust support for prompt templates and chaining together prompts in multi-step chains, enabling complex tasks that LLMs can\'t handle in a single step. This includes, but is not limited to, summarizing lengthy texts or performing advanced data processing tasks.","sidebar":"sidebar"}}}')}}]);